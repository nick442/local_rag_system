I use two measures to define investment risk: What's the longest period of time over which this investment has had negative returns? What's the worst-case fall in the value of this investment (peak to trough)? I find that the former works best for long-term investments, like retirement. As a concrete example, I have most of my retirement money in equity, since the Sensex has had zero returns over as long as a decade. Since my investment time-frame is longer, equity is risk-free, by this measure. For short-term investments, like money put aside to buy a car next year, the second measure works better. For this purpose, I might choose a debt fund that isn't the safest, and has had a worst-case 8% loss over the past decade. I can afford that loss, putting in more money from my pocket to buy the car, if needed. So, I might choose this fund for this purpose, taking a slight risk to earn higher return. In any case, how much money I need for a car can only be a rough guess, so having 8% less than originally planned may turn out to be enough. Or it may turn out that the entire amount originally planned for is insufficient, in which case a further 8% shortfall may not be a big deal. These two measures I've defined are simple to explain and understand, unlike academic stuff like beta, standard deviation, information ratio or other mumbo-jumbo. And they are simple to apply to a practical problem, as I've illustrated with the two examples above. On the other hand, if someone tells me that the standard deviation of a mutual fund is 15%, I'll have no idea what that means, or how to apply that to my financial situation. All this suffers from the problem of being limited to historical data, and the future may not be like the past. But that affects any risk statistic, and you can't do better unless you have a time machine.