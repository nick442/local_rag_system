"The formula for standard deviation is fairly simple in both the discrete and continuous cases. It's mostly safe to use the discrete case when working with adjusted closing prices. Once you've calculated the standard deviation for a given time period, the next task (in the simplest case) is to calculate the mean of that same period. This allows you to roughly approximate the distribution, which can give you all sorts of testable hypotheses. Two standard deviations (σ) away from the mean (μ) is given by: It doesn't make any sense to talk about ""two standard deviations away from the price"" unless that price is the mean or some other statistic for a given time period. Normally you would look at how far the price is from the mean, e.g. does the price fall two or three standard deviations away from the mean or some other technical indicator like the Average True Range (an exponential moving average of the True Range), some support level, another security, etc. For most of this answer, I'll assume we're using the mean for the chosen time period as a base. However, the answer is still more complicated than many people realize. As I said before, to calculate the standard deviation, you need to decide on a time period. For example, you could use S&P 500 data from Yahoo Finance and calculate the standard deviation for all adjusted closing prices since January 3, 1950. Downloading the data into Stata and applying the summarize command gives me: As you can probably see, however, these numbers don't make much sense. Looking at the data, we can see that the S&P 500 hasn't traded close to 424.4896 since November 1992. Clearly, we can't assume that this mean and standard deviation as representative of current market conditions. Furthermore, these numbers would imply that the S&P 500 is currently trading at almost three standard deviations away from its mean, which for many distribution is a highly improbable event. The Great Recession, quantitative easing, etc. may have changed the market significantly, but not to such a great extent. The problem arises from the fact that security prices are usually non-stationary. This means that the underlying distribution from which security prices are ""drawn"" shifts through time and space. For example, prices could be normally distributed in the 50's, then gamma distributed in the 60's because of a shock, then normally distributed again in the 70's. This implies that calculating summary statistics, e.g. mean, standard deviation, etc. are essentially meaningless for time periods in which prices could follow multiple distributions. For this and other reasons, it's standard practice to look at the standard deviation of returns or differences instead of prices. I covered in detail the reasons for this and various procedures to use in another answer. In short, you can calculate the first difference for each period, which is merely the difference between the closing price of that period and the closing price of the previous period. This will usually give you a stationary process, from which you can obtain more meaningful values of the standard deviation, mean, etc. Let's use the S&P500 as an example again. This time, however, I'm only using data from 1990 onwards, for the sake of simplicity (and to make the graphs a bit more manageable). The summary statistics look like this: and the graph looks like this; the mean is the central horizontal red line, and the top and bottom lines indicate one standard deviation above and below the mean, respectively. As you can see, the graph seems to indicate that there were long periods in which the index was priced well outside this range. Although this could be the case, the graph definitely exhibits a trend, along with some seemingly exogenous shocks (see my linked answer). Taking the first difference, however, yields these summary statistics: with a graph like this: This looks a lot more reasonable. In periods of recession, the price appears much more volatile, and it breaches the +/- one standard deviation lines indicated on the graph. This is only a simple summary, but using first differencing as part of the wider process of detrending/decomposing a time series is a good first step. For some technical indicators, however, stationary isn't as relevant. This is the case for some types of moving averages and their associated indicators. Take Bollinger bands for instance. These are technical indicators that show a number of standard deviations above and below a moving average. Like any calculation of standard deviation, moving average, statistic, etc. they require data over a specified time period. The analyst chooses a certain number of historical periods, e.g. 20, and calculates the moving average for that many previous periods and the moving/rolling standard deviation for those same periods as well. The Bollinger bands represent the values a certain number of standard deviations away from the moving average at a given point in time. At this given point, you can calculate the value two standard deviations ""away from the value,"" but doing so still requires the historical stock price (or at least the historical moving average). If you're only given the price in isolation, you're out of luck. Moving averages can indirectly sidestep some of the issues of stationarity I described above because it's straightforward to estimate a time series with a process built from a moving average (specifically, an auto-regressive moving average process) but the econometrics of time series is a topic for another day. The Stata code I used to generate the graphs and summary statistics:"