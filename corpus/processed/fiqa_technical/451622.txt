I wonder if any successful artificial intelligence project will ultimately need to make shortcuts that lead to the same flaws as human intelligence? (If I might pretend greater knowledge of the human mind than I have - this means: tendency to be correct to a certain level of precision rather than completely correct, to fudge, to round edges, to go by guidelines rather than rules.)