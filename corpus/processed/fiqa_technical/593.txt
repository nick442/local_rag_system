"Insurance companies on average make money by selling insurance, which means you lose money on average by dealing with them. The insurance is not gambling where the house always wins. This expression is literal in gambling, because that's how they set the odds. Insurance isn't necessarily similar. Example. Suppose there's 10% chance that $10,000 the boat sinks due to a defect. So, on average your loss is going to be $1,000. The variability of your loss measured as its standard deviation is $2,846. The variability of loss is a measure of risk. Now, let's look at two $10,000 boats. There's 1% chance that they both sink, and 18% chance that only one of them sinks. So, the expected loss is, unsurprisingly, $2,000. However, the variability of expected loss is $3,842, not quite twice the risk (variability) of a single boat accident. If you imagine that instead of a couple of boats the insurance has 100 boats, the variability of their loss (hence their risk) will increase only by a factor of 10, not 100 compared to a single boat. This means that their risk in relative terms is smaller than yours, the individual insurer's. What I tried to show was that it is possible to both of you and the insurer to benefit from the arrangement. It doesn't mean that it happens in every case, but generally it does. That's why in actuarial science there's a term fair price. UPDATE I was trying to avoid talking about utility here, because it's an involved subject, but you're dragging the discussion in this direction :) You're right that expected value cannot explain the insurance. The reason is that there's another concept that's necessary in addition to the objective measures such as expected value and risk: I mean the utility function or risk-aversion. So, in short you need to maximize expected utility, not the expected payout. Here's a toy example with the same boat. Assume that insurance is $150, and they pay the entire boat's value in case of accident, i.e. $10,000. You're given two choices effectively. At the end of the year, you have either of the following: You're right that the expected value in the second option can be higher in the second option. Let's say the probability of the loss is 10%, in this case the expected value would $9,900, which is higher than certain value of option 1. Why then some people choose option 2? The reason is that we don't maximize the expected payout, but we maximize the utility, according to modern microeconomics and game theory. Utility is some kind of an function that reflects your preference given the uncertain choices. Every person has their own preferences, and utility function. Let's say that yours is exponential with a=10000. In this case we can calculate the expected utility as follows: The math works out in such a way that it accounts for your risk tolerance. Depending on how much you love or hate risk, your expected utilities for these option will come out differently. For this given toy example it turned out that the expected utility is higher with insurance, so this person should get it. However, for different values of a parameter ""a"" in the function, it may not make a sense to insure. Some people are risk averse, some are risk lovers in certain situations. That's the reason why given the same options we make different choices. You may say that you don't value certainty enough to buy this insurance. The bottom line is that nobody can tell you that you're wrong to not buy an insurance. If your risk tolerance is high it may not make a sense for you. Having said this all, I must note that sometimes the society doesn't accept your preferences and utility function. Yes, you tell me today that you accept the risk, but tomorrow when the boat sinks you may come to me and say that you can't pay the student loan because of the hardship. That's the reason why it's mandatory to get liability insurance on cars, for instance."