Duh. Obamacare is a huge boon for health insurance companies, forcing everyone to buy their product, not providing a public option and effectively entrusting the bulk of American healthcare into the insurance companies. Of course they are going to like Obamacare. Is this really surprising?