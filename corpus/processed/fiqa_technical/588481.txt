"I think you're on the wrong track. Getting more and more samples from the real world does not make your backtest more accurate, it just confirms that your strategy can withstand one particular sample path of a stochastic process. The reason why you find it simple to incorporate fees, commissions, taxes, etc. is because they're a static and constant process -- well they might change over time but most definitely uncorrelated to the markets. Modelling overnight returns or the top levels of the order book the next day is serious work. First you have to select a suitable model (that's mostly theoretical work but experience can help a lot). Then, in order to do it data-driven, you'd have to plough through thousands of days of sample data on a set of thousands of instruments to get a ""feeling"" (aka significant model parameters). Apropos data mining, I think Excel might be the wrong tool for the job. Level-2 data (even just the first 10 levels) is a massive blob. For example, the NYSE OpenBook historical data weighs in at a massive 15 TB compressed (uncompressed 74 TB) for the last 10 years, and costs USD 200k. Anyway, as for other factors to take into account: So how to account for all this in a backtest? Personally, I would put in some penalty terms (as % on a return basis) for every factor you want to consider, don't hardcode them. You can then run a stress test by exploring these parameters (i.e. assign some values in the range of 0 to whatever fits). Explore them individually (only set one penalty term at a time) to get a feeling how the strategy might react to stress from that factor. Then you can run the backtest with typical (or observed) combinations of penalty factors and slowly stress them altogether. Edit Just to avoid confusion about terminology. A backtest in the strict sense (had I implemented this strategy X years ago, what would have happened?) won't benefit from any modelling simply because the real-world ""does the sampling"" for us. However, to evaluate a strategy's robustness you should account for the additional factors and run some stress tests. If the strategy performs well in the real-world or no-stress scenario but produces losses once a tiny slippage occurs every now and again, you could conclude that the strategy is very fragile. The key is to explore the maximum stress the strategy can handle (by whatever measure); if a lot you can call the strategy robust. The latter is what I personally call a backtest; the first procedure would go by the name ""extension towards the past"" or so. Some lightweight literature:"