I wouldn't be turned off due to the difficult of parsing English, for a few reasons. Firstly, you don't have to perfectly parse to find meaning. You can look for keywords and write some algorithms to approximate, and of course if you get enough of a statistical advantage (and can repeat it) you can make money. Second, it probably isn't long before third-party software is made available either to do something like this or to provide a framework for it. In fact, it probably already is available somewhere. (Note the influx of Silicon Valley types to New York as more machine intelligence is applied to trading and journalism.) Thirdly, as hinted by the mention above of journalism, there's already software using numerical data to write pretty human articles. Some are pretty robotic and you can catch them (I noticed one and searched for a key phrase to discover several very much like it, each having a different fake author name). This will mean not only a continued improvement of parsing but also more push for more data to be released in machine-readable formats, such that press releases will be increasingly parsible. Finally, to vindicate your idea, the keyword approach has been done with some success. Try this link and note the additional links on the same topic. If you have the time and processing resources, you might like to try your idea by training a neural network to find correlations of keywords (and phrases -- that's important, too) with trends in the market.