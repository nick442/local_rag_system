">Sorry.. I'm a software engineer not an academic. From the way you have viewed things -- that everything can be measured by quantity -- you are in fact coming from an ""academic"" perspective (the same as the ""idiot manager"" MBA's). >My assumption is that you can measure things like average throughput on a checkout line, or number of widgets assembled on an assembly line (and possibly the defect rate of those widgets), or pounds of fries dumped in the trash because they got cold before being served relative to fries served. Is this not the case? No, it is not the case; certainly not as you seem to imagine it. A single fast food worker does not simply stand in front of the french fry vats making fries all day long, and the metric of the ""fries dumped in the trash because they got cold before being served relative to fries served"" is used in the management of the overall operation (how many fries to make and when); *but they are emphatically NOT used as a 'performance measure' for the general workers (how could they be, the worker does not decide how many fries to make, the 'system' and the shift manager makes those decisions.* Likewise with the ""number of widgets assembly on the assembly line"" -- again the defect rate is known (and typically only varies when something major has gone wrong with one of the machines/processes) -- seldom is the actual worker responsible for anything major as far as defects (people with QA responsibilities might be ""thumped"" for failing to catch a bad batch -- a signal that they are likely simply NOT doing their job at all, rather than the quality of work). But the actual quantities produced are a matter of scheduling & planning via MRP systems (aka or MRP II and ERP). So, as I said.. your ignorance (which has then turned into arrogance) is showing. >In my field we measure things like the change in average time to launch, or the revenue impact of features, or the change in performance metrics, etc. LOL. The attempts to measure software engineering are among the ""most failed"" category of performance measurement. Everyone in management basically keeps repeating the same stupid mistakes that were already proven worthless in prior iterations. >They're all proxy measurements though. Poor performers are generally much easier to spot than high performers. Mediocre performers can generally get through things, but may not earn promotions etc. Don't kid yourself. Poor performers in terms of actual quality & quantity of code will often still be promoted for several ""political"" reasons; they are probably better at ""managing up"" than the better coders are (IOW, they suck up to the ""idiot manager MBA"" boss better, regurgitate the latest party line of buzzwords/phrases on a regular basis, are not seen as ""troublesome"" {adamant/insistent on quality or consistency} and are seen as ""team players"", etc.) About the only ""poor performers"" that will be easily spotted are those who are totally incompetent/unqualified -- and really, they are an indication of poor management in that they should never have been hired in the first place. And the true ""high performers"" in software are in fact fairly easy to spot -- provided you know what to look for (and don't get caught up in ridiculously inane and worthless proxy performance metrics -- which are all too often ""how well/often did you kiss the boss's arse/comply with some meaningless process steps"")."